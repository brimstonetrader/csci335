{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-30T16:18:01.259916Z","iopub.execute_input":"2023-08-30T16:18:01.260308Z","iopub.status.idle":"2023-08-30T16:18:01.305392Z","shell.execute_reply.started":"2023-08-30T16:18:01.260276Z","shell.execute_reply":"2023-08-30T16:18:01.304229Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/books-4-languages/candide.txt\n/kaggle/input/books-4-languages/zarathustra.txt\n/kaggle/input/books-4-languages/quijote.txt\n/kaggle/input/books-4-languages/wonderland.txt\n","output_type":"stream"}]},{"cell_type":"code","source":"def assess(expected, actual):\n    if expected == actual:\n        print(\"Pass\")\n    else:\n        print(f\"Fail; expected '{expected}', observed '{actual}'\")","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:18:05.420680Z","iopub.execute_input":"2023-08-30T16:18:05.421049Z","iopub.status.idle":"2023-08-30T16:18:05.426588Z","shell.execute_reply.started":"2023-08-30T16:18:05.421018Z","shell.execute_reply":"2023-08-30T16:18:05.425603Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Hidden Markov Models\n\nThis notebook uses the [hmmlearn](https://hmmlearn.readthedocs.io/en/latest/index.html) library to train a Hidden Markov Model (HMM).\n\nWe begin by including the `hmmlearn` library as well as a Python library for type annotations.","metadata":{}},{"cell_type":"code","source":"from hmmlearn import hmm\nfrom typing import *\nimport time","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:18:06.972775Z","iopub.execute_input":"2023-08-30T16:18:06.973126Z","iopub.status.idle":"2023-08-30T16:18:08.046995Z","shell.execute_reply.started":"2023-08-30T16:18:06.973096Z","shell.execute_reply":"2023-08-30T16:18:08.046102Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"To keep the model simple, we will preprocess our text inputs so that they only include lowercase letters and spaces. We will omit all punctuation and all whitespace characters that are not spaces. We will also add a leading space to each input. This process is encoded in the `filter_text()` function.","metadata":{}},{"cell_type":"code","source":"def filter_text(text: str) -> str:\n    result = \" \"\n    lowerbet = \"qwertyuiopasdfghjklzxcvbnm \"\n    upperbet = \"QWERTYUIOPASDFGHJKLZXCVBNM\"\n    for c in text:\n        if c in lowerbet:\n            result += c\n        elif c in upperbet:\n            for i in range(26):\n                if upperbet[i] == c:\n                    result += lowerbet[i]\n    return result","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:18:13.840039Z","iopub.execute_input":"2023-08-30T16:18:13.840452Z","iopub.status.idle":"2023-08-30T16:18:13.849996Z","shell.execute_reply.started":"2023-08-30T16:18:13.840418Z","shell.execute_reply":"2023-08-30T16:18:13.847347Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"assess(\" this is a test\",filter_text(\"This is a test.\"))\nassess(\" a long time ago in a galaxy far far away\", filter_text(\"A long time ago, in a galaxy far, far away...\"))","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:18:14.698028Z","iopub.execute_input":"2023-08-30T16:18:14.698413Z","iopub.status.idle":"2023-08-30T16:18:14.704723Z","shell.execute_reply.started":"2023-08-30T16:18:14.698385Z","shell.execute_reply":"2023-08-30T16:18:14.703768Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Pass\nPass\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Next, we need to be able to build a vocabulary of all possible characters. We will write the `all_distinct_characters_from()` function in order to do so.","metadata":{}},{"cell_type":"code","source":"def all_distinct_characters_from(s: str) -> List[str]:\n    result = []\n    for c in s:\n        if c not in result:\n            result += c\n    return result    ","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:18:15.804240Z","iopub.execute_input":"2023-08-30T16:18:15.804618Z","iopub.status.idle":"2023-08-30T16:18:15.813000Z","shell.execute_reply.started":"2023-08-30T16:18:15.804588Z","shell.execute_reply":"2023-08-30T16:18:15.810664Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"assess([' ', 'a', 'e', 'h', 'i', 's', 't'], sorted(all_distinct_characters_from(\"this is a test\")))","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:18:16.438375Z","iopub.execute_input":"2023-08-30T16:18:16.438752Z","iopub.status.idle":"2023-08-30T16:18:16.446624Z","shell.execute_reply.started":"2023-08-30T16:18:16.438712Z","shell.execute_reply":"2023-08-30T16:18:16.444937Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Pass\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The HMM will expect a sequence of integers rather than characters. We will use a list of characters (generated by the `all_distinct_characters_from()` function above) to transform a sequence of characters into a sequence of integers. The integers themselves need to be \"wrapped\" in lists, because tuples of integers are also acceptable emission symbols in the HMM.\n\nWe will write the `encode_sequence()` function to perform this task.","metadata":{}},{"cell_type":"code","source":"# (list of all chars in str) -> str -> [[only one int]]\ndef encode_sequence(reference_list: List[str], sequence: Iterable[str]) -> List[List[int]]:\n    result = []\n    for c in sequence:\n        for i in range(len(reference_list)):\n            if reference_list[i] == c:\n                result += [[i]]\n    return result        ","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:24:58.898431Z","iopub.execute_input":"2023-08-30T16:24:58.898874Z","iopub.status.idle":"2023-08-30T16:24:58.905978Z","shell.execute_reply.started":"2023-08-30T16:24:58.898831Z","shell.execute_reply":"2023-08-30T16:24:58.904645Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"assess([[4], [2], [0], [2], [4], [1], [3]], encode_sequence(['a', 'b', 'c', 'd', 'e'], 'ecacebd'))","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:25:01.105509Z","iopub.execute_input":"2023-08-30T16:25:01.106010Z","iopub.status.idle":"2023-08-30T16:25:01.115174Z","shell.execute_reply.started":"2023-08-30T16:25:01.105974Z","shell.execute_reply":"2023-08-30T16:25:01.113572Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Pass\n","output_type":"stream"}]},{"cell_type":"markdown","source":"To build an HMM, we [create a `hmm.CategoricalHMM()` object](https://hmmlearn.readthedocs.io/en/latest/api.html#hmmlearn.hmm.CategoricalHMM). Set the `num_components` parameter to the number of states and the `n_iter` parameter to 100. Next, call the `fit()` method with the provided sequence and assess it with the same sequence using the `score()` method. Then return both the model and the score.\n\nA correct implementation of the `build_model_score()` function should be very short:\n* Call the `hmm.CategoricalHMM()` constructor to build the model.\n* Call `fit()` to train the model.\n* Call `score()` to assess the model.","metadata":{}},{"cell_type":"code","source":"def build_model_score(num_states: int, training_sequence: List[int]) -> Tuple[hmm.CategoricalHMM, float]:\n    model = hmm.CategoricalHMM(n_components=num_states, n_iter=100)\n    model.fit(training_sequence)\n    return model, model.score(training_sequence)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:18:18.781112Z","iopub.execute_input":"2023-08-30T16:18:18.781498Z","iopub.status.idle":"2023-08-30T16:18:18.788512Z","shell.execute_reply.started":"2023-08-30T16:18:18.781466Z","shell.execute_reply":"2023-08-30T16:18:18.787272Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"Note that each run will create a different model at random. The test ensures that it has the proper number of states, and it checks to see that the score is in a reasonable range.","metadata":{}},{"cell_type":"code","source":"model, score = build_model_score(2, [[4], [2], [0], [2], [4], [1], [3]])\nif -10.0 <= score <= -6.0:\n    print(f\"Score {score} is reasonable\")\nelse:\n    print(f\"Score {score} is not plausible\")\nif type(model) == hmm.CategoricalHMM:\n    assess(model.n_components, 2)\nelse:\n    print(\"Model is not of the hmm.CategoricalHMM data type.\")","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:18:20.345985Z","iopub.execute_input":"2023-08-30T16:18:20.346478Z","iopub.status.idle":"2023-08-30T16:18:20.366955Z","shell.execute_reply.started":"2023-08-30T16:18:20.346441Z","shell.execute_reply":"2023-08-30T16:18:20.364935Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Score -9.084828290350396 is reasonable\nPass\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Not all HMMs are created equal. Some models will perform better than others. In the `build_hmm_from()` function, we will perform the following operations to find a good HMM:\n* Open the specified file and read it into a string.\n* Call `all_distinct_characters_from()` to find all the characters employed by the string.\n* Call `encode_sequence()` to encode the string as a list of lists of integers.\n* Call `build_model_score()` `num_attempts` times. Keep the HMM with the largest score.\n  * I suggest printing out the attempt number and the score for each attempt. This can\n    take quite a while to run, and seeing the scores helps convey the pace of progress.\n* Return the best model and the list of distinct characters from the input string.","metadata":{}},{"cell_type":"code","source":"def build_hmm_from(filename: str, num_states: int, num_attempts: int) -> Tuple[hmm.CategoricalHMM, List[str]]:\n    book_path = os.path.join('/kaggle/input/books-4-languages/' + filename + '.txt')\n    with open(book_path, 'r', encoding='utf-8') as book_file:\n        book = filter_text(book_file.read())\n    chars         = all_distinct_characters_from(book)\n    trainSeq      = encode_sequence(chars,book)\n    model, score  = build_model_score(num_states, trainSeq)\n    for i in range(num_attempts-1):\n        print(i+1)\n        m, s  = build_model_score(num_states, trainSeq)\n        if s > score:\n            model = m\n            score = s\n    return model, chars ","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:26:08.769342Z","iopub.execute_input":"2023-08-30T16:26:08.769776Z","iopub.status.idle":"2023-08-30T16:26:08.778291Z","shell.execute_reply.started":"2023-08-30T16:26:08.769748Z","shell.execute_reply":"2023-08-30T16:26:08.776971Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"build_hmm_from('wonderland',2,1)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:18:23.588002Z","iopub.execute_input":"2023-08-30T16:18:23.588762Z","iopub.status.idle":"2023-08-30T16:18:33.025137Z","shell.execute_reply.started":"2023-08-30T16:18:23.588728Z","shell.execute_reply":"2023-08-30T16:18:33.023165Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(CategoricalHMM(n_components=2, n_features=27, n_iter=100,\n                random_state=RandomState(MT19937) at 0x7823F0033140),\n [' ',\n  'p',\n  'r',\n  'o',\n  'j',\n  'e',\n  'c',\n  't',\n  'g',\n  'u',\n  'n',\n  'b',\n  's',\n  'a',\n  'l',\n  'i',\n  'd',\n  'v',\n  'w',\n  'y',\n  'h',\n  'k',\n  'f',\n  'm',\n  'q',\n  'x',\n  'z'])"},"metadata":{}}]},{"cell_type":"markdown","source":"There is no specific unit test for the `build_hmm_from()` function - you will have to assess it below in terms of the results it produces.\n\nOur methodology for understanding the meaning of the states of the HMM is as follows:\n* Present a sequence of characters to the HMM.\n* For each character, record which state is active.\n* For each state, count how often each character is active in that state.\n* Examining the character counts for each state, try to find a pattern that enables us to \n  say what the state represents.\n  \nThe `state_histogram()` function takes two arguments: \n* A string representing the input to an HMM.\n* A sequence of state numbers, one per character in the string.\n\nThe function returns a list of dictionaries, where each dictionary is a histogram of counts of characters that were observed in the given state.","metadata":{}},{"cell_type":"code","source":"def state_histogram(phrase: str, states: Sequence[int]) -> List[Dict[str,int]]:\n    assert len(phrase) == len(states)\n    dicts = [{}, {}]\n    for i in range(len(states)):\n        p = phrase[i]\n        s = states[i]\n        if p in dicts[s]:\n            dicts[s][p] += 1\n        else:\n            dicts[s][p] = 1\n    return dicts","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:26:59.875941Z","iopub.execute_input":"2023-08-30T16:26:59.876290Z","iopub.status.idle":"2023-08-30T16:26:59.885501Z","shell.execute_reply.started":"2023-08-30T16:26:59.876263Z","shell.execute_reply":"2023-08-30T16:26:59.883145Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"assess([{' ': 4}, {'t': 3, 'h': 1, 'i': 2, 's': 3, 'a': 1, 'e': 1}], state_histogram(\" this is a test\", [0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1]))","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:27:00.480653Z","iopub.execute_input":"2023-08-30T16:27:00.481019Z","iopub.status.idle":"2023-08-30T16:27:00.486871Z","shell.execute_reply.started":"2023-08-30T16:27:00.480990Z","shell.execute_reply":"2023-08-30T16:27:00.486126Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Pass\n","output_type":"stream"}]},{"cell_type":"markdown","source":"In the `state_histogram()` test above, state 0 corresponds to space characters, and state 1 corresponds to letters.\n\nNow that we can construct a state histogram, we will write the `interpret_states()` function, which will give us an interpretation of the HMM as follows:\n* Call `filter_text()` on the input phrase.\n* Call the `predict()` method of `hmm.CategoricalHMM` to obtain a sequence of states corresponding to the letters in the filtered input fphrase. \n  * When calling `predict()`, use the `encode_sequence()` function to encode the phrase as a sequence of integers.\n* Call `state_histogram()` and return a state histogram as described above.","metadata":{}},{"cell_type":"code","source":"def interpret_states(model: hmm.CategoricalHMM, observations: List[str], phrase: str) -> List[Dict[str,int]]:\n    text = filter_text(phrase)\n    letters = all_distinct_characters_from(text)\n    states = model.predict(encode_sequence(letters, text))\n    return state_histogram(text,states)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:30:50.504930Z","iopub.execute_input":"2023-08-30T16:30:50.505288Z","iopub.status.idle":"2023-08-30T16:30:50.512422Z","shell.execute_reply.started":"2023-08-30T16:30:50.505259Z","shell.execute_reply":"2023-08-30T16:30:50.510943Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"With `interpret_states()` completed, we can now train and interpret a full HMM. We will test it using the three English-language phrases below.","metadata":{}},{"cell_type":"code","source":"phrases = [\"one does not simply walk into mordor\",\n           \"stop trying to make fetch happen its not going to happen\",\n           \"has anyone really been far even as decided to use even go want to do look more like\"]\n\nfrases = [\"uno no entra simplemente en mordor\",\n          \"deja de intentar hacer que la búsqueda suceda, no va a suceder\",\n          \"¿Alguien realmente ha estado tan lejos como para decidir usar incluso ir y querer parecerse más\"]\n\ncordes = [\"on ne se contente pas d'entrer dans le mordor\",\n          \"Arrêtez d'essayer de faire en sorte que la récupération se produise, cela n'arrivera pas\",\n          \"Est-ce que quelqu'un a vraiment été aussi loin qu'il a décidé de l'utiliser, même s'il veut ressembler davantage à\"]\n\nsatze  = [\"Man geht nicht einfach nach Mordor\",\n          \"Hör auf zu versuchen, den Abruf zu bewerkstelligen, das wird nicht passieren\",\n          \"Ist irgendjemand wirklich so weit gekommen, dass er sich dazu entschlossen hat, sogar noch mehr auszusehen?\"]","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:30:51.564320Z","iopub.execute_input":"2023-08-30T16:30:51.564688Z","iopub.status.idle":"2023-08-30T16:30:51.571539Z","shell.execute_reply.started":"2023-08-30T16:30:51.564659Z","shell.execute_reply":"2023-08-30T16:30:51.569989Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"The experiment may take quite a while to build the model - my own solution required over two minutes. It will call `interpret_states()` for every phrase. If everything goes well, the meaning of the two states should be very clear.","metadata":{}},{"cell_type":"code","source":"# English Model - Alice In Wonderland\n\nstart = time.time()\nmodel, observations = build_hmm_from('wonderland', 2, 10)\nprint(f\"Finished building HMM after {time.time() - start} seconds.\")\nfor phrase in phrases:\n    print(phrase)\n    print(interpret_states(model, observations, phrase))","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:30:52.559269Z","iopub.execute_input":"2023-08-30T16:30:52.559804Z","iopub.status.idle":"2023-08-30T16:31:02.044376Z","shell.execute_reply.started":"2023-08-30T16:30:52.559766Z","shell.execute_reply":"2023-08-30T16:31:02.043232Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Finished building HMM after 9.476738691329956 seconds.\none does not simply walk into mordor\n[{'o': 2, 'e': 2, ' ': 6, 's': 2, 'p': 1, 'a': 1, 'r': 2}, {' ': 1, 'n': 3, 'd': 2, 'o': 4, 't': 2, 'i': 2, 'm': 2, 'l': 2, 'y': 1, 'w': 1, 'k': 1}]\nstop trying to make fetch happen its not going to happen\n[{'s': 1, 'o': 5, ' ': 10, 'r': 1, 'n': 2, 'e': 4, 'c': 1}, {' ': 1, 't': 7, 'p': 5, 'y': 1, 'i': 3, 'g': 3, 'm': 1, 'a': 3, 'k': 1, 'f': 1, 'h': 3, 'n': 3, 's': 1}]\nhas anyone really been far even as decided to use even go want to do look more like\n[{'h': 1, 's': 3, ' ': 16, 'y': 2, 'e': 4, 'l': 2, 'd': 4, 'i': 2, 'r': 1}, {' ': 2, 'a': 6, 'n': 6, 'o': 8, 'e': 9, 'r': 2, 'l': 2, 'b': 1, 'f': 1, 'v': 2, 'c': 1, 't': 3, 'u': 1, 'g': 1, 'w': 1, 'k': 2, 'm': 1}]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Spanish Model - Don Quixote\n\nstart = time.time()\nmodel, observations = build_hmm_from('quijote', 2, 1)\nprint(f\"Finished building HMM after {time.time() - start} seconds.\")\nfor phrase in phrases:\n    print(phrase)\n    print(interpret_states(model, observations, phrase))","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:39:27.302706Z","iopub.execute_input":"2023-08-30T16:39:27.303078Z","iopub.status.idle":"2023-08-30T16:39:27.311814Z","shell.execute_reply.started":"2023-08-30T16:39:27.303047Z","shell.execute_reply":"2023-08-30T16:39:27.310997Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Finished building HMM after 7.081031799316406e-05 seconds.\none does not simply walk into mordor\n[{' ': 7, 'o': 6, 'n': 3, 'e': 2, 'd': 2, 's': 2, 'i': 2, 'm': 2, 'p': 1, 'l': 2, 'y': 1, 'w': 1, 'a': 1, 'k': 1}, {'t': 2, 'r': 2}]\nstop trying to make fetch happen its not going to happen\n[{' ': 11, 's': 2, 't': 7, 'o': 5, 'p': 5, 'r': 1, 'n': 5, 'g': 3, 'm': 1, 'a': 3, 'k': 1, 'e': 4, 'f': 1, 'h': 3, 'i': 2}, {'y': 1, 'i': 1, 'c': 1}]\nhas anyone really been far even as decided to use even go want to do look more like\n[{' ': 17, 'h': 1, 'a': 6, 's': 3, 'n': 6, 'y': 2, 'e': 12, 'r': 3, 'l': 4, 'b': 1, 'f': 1, 'v': 2, 'd': 3, 't': 3, 'u': 1, 'g': 1, 'w': 1, 'k': 2, 'm': 1}, {'o': 8, 'e': 1, 'c': 1, 'i': 2, ' ': 1, 'd': 1}]\n","output_type":"stream"}]},{"cell_type":"code","source":"# French Model - Candide\n\nstart = time.time()\nmodel, observations = build_hmm_from('candide', 2, 10)\nprint(f\"Finished building HMM after {time.time() - start} seconds.\")\nfor phrase in phrases:\n    print(phrase)\n    print(interpret_states(model, observations, phrase))","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:38:38.083338Z","iopub.execute_input":"2023-08-30T16:38:38.083725Z","iopub.status.idle":"2023-08-30T16:38:49.871349Z","shell.execute_reply.started":"2023-08-30T16:38:38.083700Z","shell.execute_reply":"2023-08-30T16:38:49.869894Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Finished building HMM after 11.779870510101318 seconds.\none does not simply walk into mordor\n[{' ': 5, 'e': 2, 't': 2, 'a': 1, 'r': 2}, {'o': 6, 'n': 3, ' ': 2, 'd': 2, 's': 2, 'i': 2, 'm': 2, 'p': 1, 'l': 2, 'y': 1, 'w': 1, 'k': 1}]\nstop trying to make fetch happen its not going to happen\n[{' ': 8, 'o': 5, 'y': 1, 'e': 4, 'c': 1}, {'s': 2, 't': 7, 'p': 5, 'r': 1, 'i': 3, 'n': 5, 'g': 3, ' ': 3, 'm': 1, 'a': 3, 'k': 1, 'f': 1, 'h': 3}]\nhas anyone really been far even as decided to use even go want to do look more like\n[{' ': 11, 's': 3, 'o': 8, 'd': 2, 'i': 2}, {'h': 1, 'a': 6, ' ': 7, 'n': 6, 'y': 2, 'e': 13, 'r': 3, 'l': 4, 'b': 1, 'f': 1, 'v': 2, 'c': 1, 'd': 2, 't': 3, 'u': 1, 'g': 1, 'w': 1, 'k': 2, 'm': 1}]\n","output_type":"stream"}]},{"cell_type":"code","source":"# German Model - Thus Spoke Zarathustra\n\nstart = time.time()\nmodel, observations = build_hmm_from('zarathustra', 2, 10)\nprint(f\"Finished building HMM after {time.time() - start} seconds.\")\nfor phrase in phrases:\n    print(phrase)\n    print(interpret_states(model, observations, phrase))","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:38:55.862386Z","iopub.execute_input":"2023-08-30T16:38:55.862944Z","iopub.status.idle":"2023-08-30T16:39:24.319737Z","shell.execute_reply.started":"2023-08-30T16:38:55.862884Z","shell.execute_reply":"2023-08-30T16:39:24.318005Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Finished building HMM after 28.448261737823486 seconds.\none does not simply walk into mordor\n[{' ': 7, 'o': 6, 'n': 3, 'e': 2, 'd': 2, 's': 2, 'i': 2, 'm': 2, 'p': 1, 'l': 2, 'y': 1, 'w': 1, 'a': 1, 'k': 1}, {'t': 2, 'r': 2}]\nstop trying to make fetch happen its not going to happen\n[{' ': 11, 's': 2, 't': 7, 'o': 5, 'p': 5, 'r': 1, 'n': 5, 'g': 3, 'm': 1, 'a': 3, 'k': 1, 'e': 4, 'f': 1, 'h': 3, 'i': 2}, {'y': 1, 'i': 1, 'c': 1}]\nhas anyone really been far even as decided to use even go want to do look more like\n[{' ': 17, 'h': 1, 'a': 6, 's': 3, 'n': 6, 'y': 2, 'e': 12, 'r': 3, 'l': 4, 'b': 1, 'f': 1, 'v': 2, 'd': 3, 't': 3, 'u': 1, 'g': 1, 'w': 1, 'k': 2, 'm': 1}, {'o': 8, 'e': 1, 'c': 1, 'i': 2, ' ': 1, 'd': 1}]\n","output_type":"stream"}]}]}